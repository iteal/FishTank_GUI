{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# supress color warning when making movie\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "#%matplotlib notebook\n",
    "import time\n",
    "%load_ext autoreload\n",
    "import os\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('./lib/')\n",
    "\n",
    "from ipywidgets import Video, Image\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "from DataManagement import SplitdataManager, Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the experiment\n",
    "experiment_path = '/media/stephens-group/guest_drive/labelling/complete_shortfin_experiment/FishTank20200130_153857/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a splitdata manager\n",
    "splitman = SplitdataManager(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the names of the splitdata folders with corresponding indices\n",
    "splitdata_names = [triplet[0].split('/')[-1] for triplet in splitman.splitdata_paths]\n",
    "splitdata_idxs = [i for i in range(len(splitdata_names))]\n",
    "splitdata_name_to_idx_dict = dict(zip(splitdata_names, splitdata_idxs))\n",
    "splitdata_name_to_paths = dict(zip(splitdata_names, splitman.splitdata_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb900a9109c04c5ba738345ade5a9037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options={'splitdata0009': 0, 'splitdata0010': 1, 'splitdata0011': 2, 'splitdata0012': 3, 'splitdata00â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6455662429584f87a0d6051c4a31b9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833e9606f53449a5a22c9c352558e4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd57a3de6584095af8b7dc8e10e8b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f106a696664d28b590180699559320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  ---- choose a splitdata folder ----- #\n",
    "\n",
    "# make a dropdown menue to choose which splitdata you want\n",
    "splitdata_chooser = widgets.Dropdown(options=splitdata_name_to_idx_dict, value=0)\n",
    "\n",
    "# create and initialize widget to hold the splitdata_idx\n",
    "splitdata_idx = widgets.Output()\n",
    "with splitdata_idx:\n",
    "    display(0)\n",
    "    \n",
    "# create and initialize widget to hold the filepaths of the movies\n",
    "splitdata_paths_widget_list = [widgets.Output() for _ in range(3)]\n",
    "for i in range(3):\n",
    "    splitdata_paths = splitdata_paths_widget_list[i]\n",
    "    with splitdata_paths:\n",
    "        display(splitman.splitdata_paths[0][i])\n",
    "\n",
    "# create functions to update output widgets on changes to splitdata_chooser\n",
    "def splitdata_chooser_eventhandler_splitdata_idx(change):\n",
    "    splitdata_idx.clear_output()\n",
    "    with splitdata_idx:\n",
    "        display(change.new)\n",
    "splitdata_chooser.observe(splitdata_chooser_eventhandler_splitdata_idx, names='value')\n",
    "        \n",
    "def splitdata_chooser_eventhandler_splitdata_paths(change):\n",
    "    for i in range(3):\n",
    "        splitdata_paths = splitdata_paths_widget_list[i]\n",
    "        splitdata_paths.clear_output()\n",
    "        with splitdata_paths:\n",
    "            display(splitman.splitdata_paths[change.new][i])\n",
    "splitdata_chooser.observe(splitdata_chooser_eventhandler_splitdata_paths, names='value')\n",
    "\n",
    "\n",
    "display(splitdata_chooser, splitdata_idx)\n",
    "display(splitdata_paths_widget_list[0], splitdata_paths_widget_list[1], splitdata_paths_widget_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading tracking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trackingSavePath = '/home/liam/Downloads/fight_tracking_results_FishTank20200130_153857.h5'\n",
    "trackingSavePath = '/media/stephens-group/guest_drive/labelling/complete_shortfin_experiment/FishTank20200130_153857/fight_tracking_results_FishTank20200130_153857.h5'\n",
    "with h5py.File(trackingSavePath, 'r') as hf:\n",
    "    tracks_3D = hf['tracks_3D'][:]\n",
    "    tracks_imCoords = hf['tracks_imCoords'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501943, 2, 3, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 501943, 2, 3, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_imCoords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalnumFrames = tracks_3D.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading older trajectories\n",
    "oldPath = '/home/liam/Downloads/FishTank20200130_153857_tracks_3D.h5'\n",
    "with h5py.File(oldPath, 'r') as hf:\n",
    "    tracks_3D_old = hf['tracks_3D'][:]\n",
    "    #tracks_imCoords_old = hf['tracks_imCoords'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501943, 2, 3, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_3D_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trajectories from sLEAP tracked in the old way\n",
    "trackTestPath = '/home/liam/Data/results_from_laetitia/FishTank20200130_153857/old_tracking_on_original_instances_sLEAP.h5'\n",
    "with h5py.File(trackTestPath, 'r') as hf:\n",
    "    tracks_3D_test = hf['tracks_3D'][:]\n",
    "    #tracks_imCoords_old = hf['tracks_imCoords'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501943, 2, 3, 3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_3D_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw network results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 501943, 2, 3, 2)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the old networks WITH tatsuos annotations for training\n",
    "inst_path = '/home/liam/Data/testing_network_accuracy_in_2_fish/new_original_instances_153857.h5'\n",
    "with h5py.File(inst_path, 'r') as hf:\n",
    "    original_instances_old = hf['original_instances'][:]\n",
    "\n",
    "original_instances_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 501943, 2, 3, 2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the new networks WITH tatsuos annotations for training, after conversion to original_instances format\n",
    "inst_path = '/home/liam/Data/testing_network_accuracy_in_2_fish/original_instances_sLEAP.h5'\n",
    "with h5py.File(inst_path, 'r') as hf:\n",
    "    original_instances_new = hf['original_instances'][:]\n",
    "\n",
    "original_instances_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the raw network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.00515294075012\n"
     ]
    }
   ],
   "source": [
    "def count_numFish_found(original_instances):\n",
    "    ''' Return the number of fish found in each frame for each camera view\n",
    "    '''\n",
    "    # set all zeros to NaNs\n",
    "    original_instances = original_instances.astype('float')\n",
    "    original_instances[original_instances==0] = np.NaN\n",
    "    numCams, numFrames, numFish, numBps, _ = original_instances.shape\n",
    "    numFishFound = np.zeros((numCams, numFrames))\n",
    "    for camIdx in range(numCams):\n",
    "        for fIdx in range(numFrames):\n",
    "            fishFound = 0\n",
    "            for fishIdx in range(numFish):\n",
    "                if ~np.all(np.isnan(original_instances[camIdx, fIdx, fishIdx])):\n",
    "                    fishFound += 1\n",
    "            numFishFound[camIdx, fIdx] = fishFound\n",
    "    return numFishFound\n",
    "                    \n",
    "            \n",
    "        \n",
    "def count_numBodypoints_found(original_instances):\n",
    "    ''' Return the number of bps found in each frame for each camera view\n",
    "    '''\n",
    "    # set all zeros to NaNs\n",
    "    original_instances = original_instances.astype('float')\n",
    "    original_instances[original_instances==0] = np.NaN\n",
    "    numCams, numFrames, numFish, numBps, _ = original_instances.shape\n",
    "    numBps_arr = np.zeros((numCams, numFrames))\n",
    "    for camIdx in range(numCams):\n",
    "        for fIdx in range(numFrames):\n",
    "            numBps_found = 0\n",
    "            for fishIdx in range(numFish):\n",
    "                for bpIdx in range(numBps):\n",
    "                    if ~np.all(np.isnan(original_instances[camIdx, fIdx, fishIdx, bpIdx])):\n",
    "                        numBps_found += 1\n",
    "            #import pdb; pdb.set_trace()\n",
    "            numBps_arr[camIdx, fIdx] = numBps_found\n",
    "    return numBps_arr\n",
    "\n",
    "\n",
    "\n",
    "# get the number of fish and bps found by for each data\n",
    "t0 = time.time()\n",
    "\n",
    "# old\n",
    "numFish_found_old = count_numFish_found(original_instances_old)\n",
    "numFish_found_mean_old = np.mean(numFish_found_old, axis=1)\n",
    "numBps_found_old = count_numBodypoints_found(original_instances_old)\n",
    "numBps_found_mean_old = np.mean(numBps_found_old, axis=1)\n",
    "\n",
    "# sLEAP\n",
    "numFish_found_new = count_numFish_found(original_instances_new)\n",
    "numFish_found_mean_new = np.mean(numFish_found_new, axis=1)\n",
    "numBps_found_new = count_numBodypoints_found(original_instances_new)\n",
    "numBps_found_mean_new = np.mean(numBps_found_new, axis=1)\n",
    "\n",
    "tE = time.time()\n",
    "print(tE-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Old --\n",
      "[1.5443905  1.93911859 1.3730822 ]\n",
      "[4.47758809 5.70549246 4.08892245]\n",
      "\n",
      "-- new --\n",
      "[1.80652983 1.9634082  1.83032934]\n",
      "[5.37825809 5.86898911 5.43987066]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-- Old --')\n",
    "print(numFish_found_mean_old)\n",
    "print(numBps_found_mean_old)\n",
    "print()\n",
    "\n",
    "print('-- new --')\n",
    "print(numFish_found_mean_new)\n",
    "print(numBps_found_mean_new)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the trajectory level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Percentage of frames with full information --\n",
      "Old networks: 68.07705257369861 %\n",
      "New networks: 85.2467312025469 %\n",
      "\n",
      "----\n",
      "time:  5.74419379234314 s\n"
     ]
    }
   ],
   "source": [
    "# How many frames have full information? \n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "full_data_test = np.zeros((totalnumFrames,))\n",
    "full_data_old = np.zeros((totalnumFrames,))\n",
    "\n",
    "for fIdx in range(totalnumFrames):\n",
    "\n",
    "    f_data_test = tracks_3D_test[fIdx]\n",
    "    f_data_old = tracks_3D_old[fIdx]\n",
    "\n",
    "    if ~np.any(np.isnan(f_data_test)):\n",
    "        full_data_test[fIdx] = 1\n",
    "        \n",
    "    if ~np.any(np.isnan(f_data_old)):\n",
    "        full_data_old[fIdx] = 1\n",
    "        \n",
    "        \n",
    "counts, vals = np.unique(full_data_old, return_counts=True)\n",
    "old_full_data_summary = list(zip(counts, vals))\n",
    "old_full_fraction = old_full_data_summary[1][1] / totalnumFrames\n",
    "\n",
    "counts, vals = np.unique(full_data_test, return_counts=True)\n",
    "test_full_data_summary = list(zip(counts, vals))\n",
    "test_full_fraction = test_full_data_summary[1][1] / totalnumFrames\n",
    "\n",
    "print('-- Percentage of frames with full information --')\n",
    "print('Old networks: {0} %'.format(old_full_fraction*100))\n",
    "print('New networks: {0} %'.format(test_full_fraction*100))\n",
    "     \n",
    "        \n",
    "print()\n",
    "print('----')\n",
    "tE = time.time()\n",
    "print('time: ', tE-t0, 's')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Percentage of frames with some information --\n",
      "Old networks: 87.33401999828666 %\n",
      "New networks: 97.5983328784344 %\n",
      "\n",
      "----\n",
      "time:  5.816539287567139 s\n"
     ]
    }
   ],
   "source": [
    "# How many frames have at least some information\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "some_fish_data_test = np.zeros((totalnumFrames,))\n",
    "some_fish_data_old = np.zeros((totalnumFrames,))\n",
    "\n",
    "for fIdx in range(totalnumFrames):\n",
    "\n",
    "    f_data_test = tracks_3D_test[fIdx]\n",
    "    f_data_old = tracks_3D_old[fIdx]\n",
    "\n",
    "    if ~np.all(np.isnan(f_data_test)):\n",
    "        some_fish_data_test[fIdx] = 1\n",
    "        \n",
    "    if ~np.all(np.isnan(f_data_old)):\n",
    "        some_fish_data_old[fIdx] = 1\n",
    "        \n",
    "        \n",
    "counts, vals = np.unique(some_fish_data_old, return_counts=True)\n",
    "old_some_fish_data_summary = list(zip(counts, vals))\n",
    "old_some_fish_fraction = old_some_fish_data_summary[1][1] / totalnumFrames\n",
    "\n",
    "counts, vals = np.unique(some_fish_data_test, return_counts=True)\n",
    "test_some_fish_data_summary = list(zip(counts, vals))\n",
    "test_some_fish_fraction = test_some_fish_data_summary[1][1] / totalnumFrames\n",
    "\n",
    "print('-- Percentage of frames with some information --')\n",
    "print('Old networks: {0} %'.format(old_some_fish_fraction*100))\n",
    "print('New networks: {0} %'.format(test_some_fish_fraction*100))\n",
    "     \n",
    "        \n",
    "print()\n",
    "print('----')\n",
    "tE = time.time()\n",
    "print('time: ', tE-t0, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full info: 85.2467312025469 %\n",
    "Some info: 97.59 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5329dc734b2e41b583ce6a44da782da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='w', max=501943), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_ts(w=0)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_ts(w=0):\n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    fishIdx=0\n",
    "    bpIdx=2\n",
    "    f1hx = tracks_3D[0+w:100+w, fishIdx, bpIdx, 0] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 0])\n",
    "    #f1hy = tracks_3D[0+w:100+w, fishIdx, bpIdx, 1] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 1])\n",
    "    #f1hz = tracks_3D[0+w:100+w, fishIdx, bpIdx, 2] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 2])\n",
    "    \n",
    "    fishIdx=0\n",
    "    bpIdx=2\n",
    "    ## USING SAME MEAN FOR SUBTRACTION\n",
    "    f1hx_old = tracks_3D_old[0+w:100+w, fishIdx, bpIdx, 0] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 0])\n",
    "    #f1hy = tracks_3D[0+w:100+w, fishIdx, bpIdx, 1] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 1])\n",
    "    #f1hz = tracks_3D[0+w:100+w, fishIdx, bpIdx, 2] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 2])\n",
    "    \n",
    "    \n",
    "    fishIdx=0\n",
    "    bpIdx=2\n",
    "    ## USING SAME MEAN FOR SUBTRACTION\n",
    "    f1hx_test = tracks_3D_test[0+w:100+w, fishIdx, bpIdx, 0] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 0])\n",
    "    #f1hy = tracks_3D[0+w:100+w, fishIdx, bpIdx, 1] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 1])\n",
    "    #f1hz = tracks_3D[0+w:100+w, fishIdx, bpIdx, 2] - np.nanmean(tracks_3D[0+w:100+w, fishIdx, bpIdx, 2])\n",
    "    \n",
    "    \n",
    "    ax.plot(f1hx, label='f1hx_new')\n",
    "    ax.plot(f1hx_old, label='f1hx_old')\n",
    "    ax.plot(f1hx_test, label='f1hx_test')\n",
    "    \n",
    "#     ax.plot(f1hx, label='f1hx')\n",
    "#     ax.plot(f1hy, label='f1hy')\n",
    "#     ax.plot(f1hz, label='f1hz')\n",
    "    ax.set_ylim(-10,10)\n",
    "    fig.canvas.draw()\n",
    "    ax.legend()\n",
    "    \n",
    "interact(plot_ts, w=widgets.IntSlider(min=0,max=totalnumFrames,step=1,value=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fstart = 80000\n",
    "global_fstop = global_fstart + 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "splitdata0022\n",
      "2000\n",
      "\n",
      "13\n",
      "splitdata0022\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "# get the local info\n",
    "splitdata_idx1, local_fstart = splitman.return_splitdata_folder_and_local_idx_for_global_frameIdx(global_fstart, return_splitdataIdx=True)\n",
    "splitdata_name1 = splitdata_names[splitdata_idx1]\n",
    "print(splitdata_idx1)\n",
    "print(splitdata_name1)\n",
    "print(local_fstart)\n",
    "print()\n",
    "splitdata_idx2, local_fstop = splitman.return_splitdata_folder_and_local_idx_for_global_frameIdx(global_fstop, return_splitdataIdx=True)\n",
    "splitdata_name2 = splitdata_names[splitdata_idx2]\n",
    "print(splitdata_idx2)\n",
    "print(splitdata_name2)\n",
    "print(local_fstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/stephens-group/guest_drive/labelling/complete_shortfin_experiment/FishTank20200130_153857/D_xz/splitdata0022.mp4',\n",
       " '/media/stephens-group/guest_drive/labelling/complete_shortfin_experiment/FishTank20200130_153857/E_xy/splitdata0022.mp4',\n",
       " '/media/stephens-group/guest_drive/labelling/complete_shortfin_experiment/FishTank20200130_153857/F_yz/splitdata0022.mp4']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the movie paths\n",
    "# idx1 == idx2\n",
    "paths = splitman.splitdata_paths[splitdata_idx1]\n",
    "video_paths = [path +'.mp4' for path in paths]\n",
    "video_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather the data for this section of frames\n",
    "xz_tracks = np.copy(tracks_imCoords[0, global_fstart:global_fstop])\n",
    "xy_tracks = np.copy(tracks_imCoords[1, global_fstart:global_fstop])\n",
    "yz_tracks = np.copy(tracks_imCoords[2, global_fstart:global_fstop])\n",
    "tra_3D = np.copy(tracks_3D[global_fstart:global_fstop])\n",
    "numFrames = global_fstop - global_fstart\n",
    "\n",
    "numFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6971e58ff23c4566a091e130c254bbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='w', max=200), Output()), _dom_classes=('widget-interact'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update(w=1)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update(w=1):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    frame = make_3D_plot_of_frame_positions(tra_3D[w])\n",
    "    ax.imshow(frame)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "interact(update, w=widgets.IntSlider(min=0,max=numFrames,step=1,value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2, 3, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xz_tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the centers\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "def fill_nan(A):\n",
    "    '''\n",
    "    Thanks - https://stackoverflow.com/a/9815522\n",
    "    interpolate to fill nan values\n",
    "    '''\n",
    "    inds = np.arange(A.shape[0])\n",
    "    good = np.where(np.isfinite(A))\n",
    "    f = interpolate.interp1d(inds[good], A[good],bounds_error=False)\n",
    "    B = np.where(np.isfinite(A),A,f(inds))\n",
    "    return B\n",
    "\n",
    "# interpolate the fish_pecs so we dont blink\n",
    "xz_heads = np.copy(xz_tracks[:,:,0])\n",
    "xy_heads = np.copy(xy_tracks[:,:,0])\n",
    "yz_heads = np.copy(yz_tracks[:,:,0])\n",
    "xz_heads_interpd = np.copy(xz_heads)\n",
    "xy_heads_interpd = np.copy(xy_heads)\n",
    "yz_heads_interpd = np.copy(yz_heads)\n",
    "\n",
    "for fishIdx in range(2):\n",
    "    xz_heads_x = np.copy(xz_heads[:, fishIdx, 0])\n",
    "    xz_heads_y = np.copy(xz_heads[:, fishIdx, 1])\n",
    "    xz_heads_x_interpd = fill_nan(xz_heads_x)\n",
    "    xz_heads_y_interpd = fill_nan(xz_heads_y)\n",
    "    xz_heads_interpd[:, fishIdx, 0] = xz_heads_x_interpd\n",
    "    xz_heads_interpd[:, fishIdx, 1] = xz_heads_y_interpd\n",
    "    \n",
    "    xy_heads_x = np.copy(xy_heads[:, fishIdx, 0])\n",
    "    xy_heads_y = np.copy(xy_heads[:, fishIdx, 1])\n",
    "    xy_heads_x_interpd = fill_nan(xy_heads_x)\n",
    "    xy_heads_y_interpd = fill_nan(xy_heads_y)\n",
    "    xy_heads_interpd[:, fishIdx, 0] = xy_heads_x_interpd\n",
    "    xy_heads_interpd[:, fishIdx, 1] = xy_heads_y_interpd\n",
    "    \n",
    "    yz_heads_x = np.copy(yz_heads[:, fishIdx, 0])\n",
    "    yz_heads_y = np.copy(yz_heads[:, fishIdx, 1])\n",
    "    yz_heads_x_interpd = fill_nan(yz_heads_x)\n",
    "    yz_heads_y_interpd = fill_nan(yz_heads_y)\n",
    "    yz_heads_interpd[:, fishIdx, 0] = yz_heads_x_interpd\n",
    "    yz_heads_interpd[:, fishIdx, 1] = yz_heads_y_interpd\n",
    "    \n",
    "    \n",
    "crop_centers = [xz_heads_interpd, xy_heads_interpd, yz_heads_interpd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fstart 2000\n",
      "fstop 2200\n",
      "2000\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "movieSavePath = '/home/liam/temp/mov1.mp4'\n",
    "\n",
    "make_3panel_movie(video_paths, xy_tracks, xz_tracks, yz_tracks, movieSavePath, \n",
    "                  crop_centers, cropSize=(80,80), bw=20, padding_depth=70,\n",
    "                  fstart=local_fstart, fstop=local_fstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a movie of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_frame(frame, padding_depth):\n",
    "    ''' Return a padded version of the frame '''\n",
    "    # grab the padding from the image\n",
    "    padding = frame[0:padding_depth,:]\n",
    "    # make the padded frame\n",
    "    frame = np.vstack((padding, frame, padding))\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a movie\n",
    "\n",
    "def make_3panel_movie(video_paths, xy_tracks, xz_tracks, yz_tracks, movieSavePath, \n",
    "                      crop_centers, cropSize=(80,80), bw=20, padding_depth=70,\n",
    "                      fstart=0, fstop=6000):\n",
    "    \"\"\" Visualize the sLEAP and idTracker data drawn onto the movie\n",
    "    \n",
    "    -- args --\n",
    "    video_path: the filepath of the splitdata.mp4\n",
    "    **_tracks: the tracked trajectories from the ** camera\n",
    "    movieSavePath: the filepath to save the new mp4 to\n",
    "    crop_centers: these are interpolated timeseries of head position, that are\n",
    "                  used from cropping when making the movie\n",
    "    \n",
    "    \"\"\"\n",
    "    print('fstart', fstart)\n",
    "    print('fstop', fstop)\n",
    "    \n",
    "    # set up the video maker\n",
    "    fps = 100\n",
    "    fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "    resolution = (480+bw+bw, 160) # cols/rows\n",
    "    out = cv2.VideoWriter(movieSavePath, fourcc, fps, resolution)\n",
    "    \n",
    "    # parse some shapes\n",
    "    numFrames, numFish, numBodyPoints, _ = xy_tracks.shape\n",
    "    if numFrames > fstop:\n",
    "        fstop = numFrames\n",
    "    \n",
    "    # make a list of colors\n",
    "    colors = [(0,255,0), (255,255,255)] # blue and green\n",
    "    \n",
    "    # open the caps\n",
    "    caps = [cv2.VideoCapture(video_path) for video_path in video_paths]\n",
    "    \n",
    "    # pack up the tracks\n",
    "    tracks = [xz_tracks, xy_tracks, yz_tracks]\n",
    "    \n",
    "    frame_index = 0\n",
    "    while caps[0].isOpened() and caps[1].isOpened() and caps[2].isOpened():\n",
    "            \n",
    "        # grab the 3 images\n",
    "        ret_xz, frame_xz = caps[0].read()\n",
    "        if not ret_xz:\n",
    "            break\n",
    "        ret_xy, frame_xy = caps[1].read()\n",
    "        if not ret_xy:\n",
    "            break\n",
    "        ret_yz, frame_yz = caps[2].read()\n",
    "        if not ret_yz:\n",
    "            break\n",
    "        frames = [frame_xz, frame_xy, frame_yz]\n",
    "        \n",
    "        if frame_index < fstart:\n",
    "            frame_index += 1\n",
    "            continue\n",
    "    \n",
    "        # update message\n",
    "        if np.mod(frame_index, 100) == 0:\n",
    "            print(frame_index)\n",
    "        \n",
    "        # draw the info\n",
    "        for camIdx in range(3):\n",
    "            frame = frames[camIdx]\n",
    "            trks = tracks[camIdx]\n",
    "            for fishIdx in range(numFish):\n",
    "                for bpIdx in range(numBodyPoints):\n",
    "                    # get the data\n",
    "                    imCoord = trks[frame_index-fstart, fishIdx, bpIdx]\n",
    "                    #get the color\n",
    "                    color = colors[fishIdx]\n",
    "                    color = ( int (color[ 0 ]), int(color[ 1 ]), int(color[ 2 ]))\n",
    "                    if np.all(np.isnan(imCoord)):\n",
    "                        continue\n",
    "                    cv2.circle(frame, (int(imCoord[0]), int(imCoord[1])), radius=2, color=color, thickness=-1)\n",
    "                    \n",
    "        # take crops around fish1\n",
    "        crops = []\n",
    "        for camIdx in range(3):\n",
    "            fish1_head = crop_centers[camIdx][frame_index-fstart, 0]\n",
    "            # get the center of the crop, adjusted for padding\n",
    "            cropCenter = [fish1_head[0], fish1_head[1]+padding_depth]\n",
    "            \n",
    "            if np.all(np.isnan(fish1_head)):\n",
    "                crop = np.zeros((cropSize[0]*2, cropSize[1]*2, 3), dtype=np.uint8)\n",
    "                crops.append(crop)\n",
    "            else:\n",
    "                frame = frames[camIdx]\n",
    "                frame = _pad_frame(frame, padding_depth)\n",
    "                crop = frame[int(cropCenter[1]-cropSize[1]):int(cropCenter[1]+cropSize[1]),\n",
    "                             int(cropCenter[0]-cropSize[0]):int(cropCenter[0]+cropSize[0])]\n",
    "                crops.append(crop)\n",
    "            \n",
    "        # combine the crops\n",
    "        barrier = np.zeros((cropSize[0]*2, bw, 3), dtype=np.uint8)\n",
    "        movFrame = np.hstack([crops[0], barrier, crops[1], barrier, crops[2]])\n",
    "        #movFrame = cv2.resize(movFrame, resolution, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        # write the frame number\n",
    "        x1, y1 = 10,10\n",
    "        label = str(frame_index).zfill(6)\n",
    "        cv2.putText(movFrame,label,(x1,y1),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,0),1)\n",
    "        # write the frame\n",
    "        out.write(movFrame)\n",
    "        frame_index += 1\n",
    "        if frame_index >= fstop:\n",
    "            break\n",
    "        \n",
    "    # close everything before we finish\n",
    "    for capIdx in range(3):\n",
    "        caps[capIdx].release()\n",
    "    out.release() \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function for making a 3D visualization of the fish in 3D for a frame\n",
    "# This function is useful because it returns a regular image array, not a matplotlib figure or something\n",
    "# This makes it much easier to write in a movie\n",
    "\n",
    "def make_3D_plot_of_frame_positions(f_positions):\n",
    "    ''' Given the frame positions, return a 3D plot of the positions of this fish in\n",
    "        array form\n",
    "    '''\n",
    "    # turn off interactive plots for now\n",
    "    plt.ioff()\n",
    "\n",
    "    # get the number of bps and numFish\n",
    "    numFish = f_positions.shape[0]\n",
    "    numBps = f_positions.shape[1]\n",
    "\n",
    "    # make a figure and canvas\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    fig.tight_layout(pad=0)\n",
    "    canvas = FigureCanvas(fig)\n",
    "    fig.add_subplot(111, projection='3d')\n",
    "    ax = fig.gca()\n",
    "\n",
    "    #loop over fish\n",
    "    for f in range(numFish):\n",
    "\n",
    "            \n",
    "        # decide on the color\n",
    "        if f == 0:\n",
    "            c_real = [0,0,1,1]\n",
    "            c_projection = [0,0,1,0.15]\n",
    "        elif f == 1:\n",
    "            c_real = [1,0,0,1]\n",
    "            c_projection = [1,0,0,0.15]\n",
    "        else:\n",
    "            raise TypeError('Need to define more colors')\n",
    "\n",
    "        # get the positions of the bps for this fish\n",
    "        f_pos = f_positions[f]\n",
    "\n",
    "        #  -- real -- #\n",
    "        # plot each of the points\n",
    "        ax.scatter(f_pos[0,0], f_pos[0,1], f_pos[0,2], c=c_real, marker='D', depthshade=False, s=40)\n",
    "        ax.scatter(f_pos[1,0], f_pos[1,1], f_pos[1,2], c=c_real, marker='x', depthshade=False, s=40)\n",
    "        ax.scatter(f_pos[2,0], f_pos[2,1], f_pos[2,2], c=c_real, marker='.', depthshade=False, s=40)\n",
    "        # use plot3D to draw lines to join these points\n",
    "        ax.plot3D(f_pos[:, 0], f_pos[:, 1], f_pos[:, 2], color=c_real, linewidth=2)\n",
    "\n",
    "        # -- XY projection -- #\n",
    "        # we want to set the Z coord of everypoint to 0\n",
    "        # color is red with alpha layer\n",
    "        ax.scatter(f_pos[0,0], f_pos[0,1], 0, c=c_projection, marker='D', depthshade=False, s=40)\n",
    "        ax.scatter(f_pos[1,0], f_pos[1,1], 0, c=c_projection, marker='x', depthshade=False, s=40)\n",
    "        ax.scatter(f_pos[2,0], f_pos[2,1], 0, c=c_projection, marker='.', depthshade=False, s=40)\n",
    "        # use plot3D to draw lines to join these points\n",
    "        ax.plot3D(f_pos[:, 0], f_pos[:, 1], np.zeros((numBps,)), c=c_projection, linewidth=2)\n",
    "\n",
    "        # -- XZ projection -- #\n",
    "        # we want to set the Y coord of everypoint to 0\n",
    "        # color is red with alpha layer\n",
    "        ax.scatter(f_pos[0,0], 0, f_pos[0,2], c=c_projection, marker='D', depthshade=False, s=40)\n",
    "        ax.scatter(f_pos[1,0], 0, f_pos[1,2], c=c_projection, marker='x', depthshade=False, s=40)\n",
    "        ax.scatter(f_pos[2,0], 0, f_pos[2,2], c=c_projection, marker='.', depthshade=False, s=40)\n",
    "        # use plot3D to draw lines to join these points\n",
    "        ax.plot3D(f_pos[:,0], np.zeros((numBps,)), f_pos[:,2], c=c_projection, linewidth=2)\n",
    "\n",
    "        # -- YZ projection -- #\n",
    "        # we want to set the X coord of everypoint to 0\n",
    "        # color is red with alpha layer\n",
    "        ax.scatter(0, f_pos[0,1], f_pos[0,2], c=c_projection, marker='D', depthshade=False, s=40)\n",
    "        ax.scatter(0, f_pos[1,1], f_pos[1,2], c=c_projection, marker='x', depthshade=False, s=40)\n",
    "        ax.scatter(0, f_pos[2,1], f_pos[2,2], c=c_projection, marker='.', depthshade=False, s=40)\n",
    "        # use plot3D to draw lines to join these points\n",
    "        ax.plot3D(np.zeros((numBps,)), f_pos[:,1], f_pos[:,2], c=c_projection, linewidth=2)\n",
    "\n",
    "\n",
    "    # make the plot pretty\n",
    "    ax.set_xlabel('X (cm)', fontsize=20)\n",
    "    ax.set_ylabel('Y (cm)', fontsize=20)\n",
    "    ax.set_zlabel('Z (cm)', fontsize=20)\n",
    "    ax.set_xlim(0,40)\n",
    "    ax.set_ylim(0,40)\n",
    "    ax.set_zlim(0,40)\n",
    "    ticks = [0, 10, 20, 30, 40]\n",
    "    ax.set_xticks(ticks, minor=False)\n",
    "    ax.set_yticks(ticks, minor=False)\n",
    "    #ax.grid(False)\n",
    "\n",
    "    # set the angle of viewing\n",
    "    elevation_angle = 10\n",
    "    azimuthal_angle = 45\n",
    "    ax.view_init(elevation_angle, azimuthal_angle)\n",
    "\n",
    "    # draw the canvas\n",
    "    canvas.draw()\n",
    "\n",
    "    # get the width and height of the figure, and turn them to type ints\n",
    "    height, width = fig.get_size_inches() * fig.get_dpi()\n",
    "    width = width.astype('int')\n",
    "    height = height.astype('int')\n",
    "\n",
    "    # convert the figure to an array of the correct size\n",
    "    img = np.frombuffer(canvas.tostring_rgb(), dtype='uint8').reshape(width, height, 3)\n",
    "\n",
    "    # close the figure - we are done. You can also turn back on interactive plots now\n",
    "    plt.close()\n",
    "    plt.ion()\n",
    "\n",
    "    # lastly remove some of the white space from around the frame\n",
    "    # NOTE: IF YOU CHANGE FIGURE SIZE YOU WILL HAVE TO CHANGE THIS\n",
    "    #       THIS IS A MANUAL WAY TO REMOVE WHITESPACE\n",
    "    #img = img[325:1225, 250:1265]\n",
    "    img = img[300:900, 150:1000]\n",
    "\n",
    "    # return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "camIdx = 0\n",
    "movPath = splitdata_paths_widget_list[camIdx].outputs[0]['data']['text/plain'][1:-1] + '.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Video.from_file(movPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\xf95\\xf1mdat\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FishTank",
   "language": "python",
   "name": "fishtank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
